{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Concepts\n",
    "\n",
    "This tutorial covers the fundamental building blocks of iTuna:\n",
    "\n",
    "1. **ConsistencyEnsemble** - The main class for evaluating model consistency\n",
    "2. **Indeterminacy classes** - How to handle different types of model ambiguity\n",
    "3. **Consistency scoring** - Measuring and interpreting consistency\n",
    "4. **Working with embeddings** - Accessing aligned representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hkfs/home/haicore/hgf_hmgu/hgf_sfs7789/git/itune-ref/ituna/_backends/utils.py:22: UserWarning: config_dataclass is not available, saving/loading Configurable objects will not be available\n",
      "  warnings.warn(\"config_dataclass is not available, saving/loading Configurable objects will not be available\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "\n",
    "import ituna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConsistencyEnsemble\n",
    "\n",
    "`ConsistencyEnsemble` is iTuna's main class. It wraps any sklearn-compatible transformer and:\n",
    "\n",
    "1. Creates multiple clones of the base estimator\n",
    "2. Fits each clone with a different random seed\n",
    "3. Aligns the resulting embeddings under the specified indeterminacy\n",
    "4. Computes consistency scores across all model pairs\n",
    "\n",
    "### Requirements for the base estimator\n",
    "\n",
    "Your model must follow the sklearn API:\n",
    "- Implement `fit(X)` and `transform(X)` methods\n",
    "- Be clonable via `sklearn.base.clone()`\n",
    "- Accept a `random_state` parameter (for reproducibility)\n",
    "\n",
    "Most sklearn transformers work out of the box. For custom models, inherit from `sklearn.base.TransformerMixin` and `sklearn.base.BaseEstimator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indeterminacy Classes\n",
    "\n",
    "Different representation learning algorithms are identifiable up to different classes of transformations. iTuna provides four built-in indeterminacy classes:\n",
    "\n",
    "| Class | Transformation | Example Models |\n",
    "|-------|---------------|----------------|\n",
    "| `Identity` | None (exact match) | Fully identifiable models |\n",
    "| `Permutation` | Sign flips + reordering | FastICA, sparse coding |\n",
    "| `Linear` | Linear transformation | PCA, factor analysis |\n",
    "| `Affine` | Linear + intercept | CEBRA, autoencoders |\n",
    "\n",
    "Choosing the correct indeterminacy class is crucial: if you pick one that's too restrictive, consistent models will appear inconsistent. If you pick one that's too permissive, you may miss genuine inconsistencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: FastICA with Permutation indeterminacy\n",
    "\n",
    "Independent Component Analysis (ICA) recovers independent sources from mixed signals. The recovered components are identifiable up to **permutation and sign flips** - we don't know which component is which, or whether it's flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic ICA data\n",
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "n_sources = 5\n",
    "\n",
    "# Create independent sources\n",
    "t = np.linspace(0, 10, n_samples)\n",
    "sources = np.column_stack([\n",
    "    np.sin(2 * t),           # Sinusoid\n",
    "    np.sign(np.sin(3 * t)),  # Square wave\n",
    "    np.random.laplace(size=n_samples),  # Super-Gaussian\n",
    "    np.random.uniform(-1, 1, n_samples),  # Uniform\n",
    "    (t % 1) - 0.5,           # Sawtooth\n",
    "])\n",
    "\n",
    "# Mix the sources\n",
    "mixing_matrix = np.random.randn(n_sources, n_sources)\n",
    "X_ica = sources @ mixing_matrix.T\n",
    "X_ica += 0.1 * np.random.randn(*X_ica.shape)  # Add noise\n",
    "\n",
    "print(f\"Data shape: {X_ica.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA Consistency score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create a FastICA model\n",
    "ica_model = FastICA(n_components=5, max_iter=1000)\n",
    "\n",
    "# Wrap in ConsistencyEnsemble with Permutation indeterminacy\n",
    "ica_ensemble = ituna.ConsistencyEnsemble(\n",
    "    estimator=ica_model,\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=ituna.metrics.Permutation(),\n",
    "        symmetric=False,\n",
    "        include_diagonal=True,\n",
    "    ),\n",
    "    random_states=5,  # Train 5 models with different seeds\n",
    ")\n",
    "\n",
    "# Fit the ensemble\n",
    "ica_ensemble.fit(X_ica)\n",
    "\n",
    "# Get consistency score\n",
    "score = ica_ensemble.score(X_ica)\n",
    "print(f\"ICA Consistency score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: PCA with Linear indeterminacy\n",
    "\n",
    "PCA finds orthogonal directions of maximum variance. The principal components are identifiable up to **linear transformations** (rotations and reflections within eigenspaces of equal variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Consistency score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Generate data for PCA\n",
    "np.random.seed(42)\n",
    "X_pca = np.random.randn(1000, 20)\n",
    "\n",
    "# Create PCA model\n",
    "pca_model = PCA(n_components=5)\n",
    "\n",
    "# Wrap in ConsistencyEnsemble with Linear indeterminacy\n",
    "pca_ensemble = ituna.ConsistencyEnsemble(\n",
    "    estimator=pca_model,\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=ituna.metrics.Linear(),\n",
    "        symmetric=False,\n",
    "        include_diagonal=True,\n",
    "    ),\n",
    "    random_states=5,\n",
    ")\n",
    "\n",
    "pca_ensemble.fit(X_pca)\n",
    "score = pca_ensemble.score(X_pca)\n",
    "print(f\"PCA Consistency score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Consistency Scores\n",
    "\n",
    "The consistency score measures how well embeddings from different model instances align after accounting for the indeterminacy. \n",
    "\n",
    "- **Score = 1.0**: Perfect consistency - all models produce equivalent embeddings\n",
    "- **Score close to 1.0**: High consistency - models are reliably converging to the same solution\n",
    "- **Low score**: Models are finding different solutions, suggesting the representation may not be reproducible\n",
    "\n",
    "The score is computed as the R² between embeddings after fitting the indeterminacy transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Embeddings\n",
    "\n",
    "After fitting, you can access the embeddings and alignment information via `transform()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean aligned embedding shape: (2000, 5)\n",
      "Number of individual model embeddings: 5\n",
      "  Model 0 embedding shape: (2000, 5)\n",
      "  Model 1 embedding shape: (2000, 5)\n",
      "  Model 2 embedding shape: (2000, 5)\n",
      "  Model 3 embedding shape: (2000, 5)\n",
      "  Model 4 embedding shape: (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings with alignment metadata\n",
    "embeddings = ica_ensemble.transform(X_ica)\n",
    "\n",
    "print(f\"Mean aligned embedding shape: {embeddings.shape}\")\n",
    "print(f\"Number of individual model embeddings: {len(embeddings.embeddings)}\")\n",
    "\n",
    "# Access individual embeddings\n",
    "for i, emb in enumerate(embeddings.embeddings):\n",
    "    print(f\"  Model {i} embedding shape: {emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise consistency scores:\n",
      "  Model 0 -> Model 0: 1.0000\n",
      "  Model 0 -> Model 1: 1.0000\n",
      "  Model 0 -> Model 2: 1.0000\n",
      "  Model 0 -> Model 3: 1.0000\n",
      "  Model 0 -> Model 4: 1.0000\n",
      "  Model 1 -> Model 0: 1.0000\n",
      "  Model 1 -> Model 1: 1.0000\n",
      "  Model 1 -> Model 2: 1.0000\n",
      "  Model 1 -> Model 3: 1.0000\n",
      "  Model 1 -> Model 4: 1.0000\n",
      "  Model 2 -> Model 0: 1.0000\n",
      "  Model 2 -> Model 1: 1.0000\n",
      "  Model 2 -> Model 2: 1.0000\n",
      "  Model 2 -> Model 3: 1.0000\n",
      "  Model 2 -> Model 4: 1.0000\n",
      "  Model 3 -> Model 0: 1.0000\n",
      "  Model 3 -> Model 1: 1.0000\n",
      "  Model 3 -> Model 2: 1.0000\n",
      "  Model 3 -> Model 3: 1.0000\n",
      "  Model 3 -> Model 4: 1.0000\n",
      "  Model 4 -> Model 0: 1.0000\n",
      "  Model 4 -> Model 1: 1.0000\n",
      "  Model 4 -> Model 2: 1.0000\n",
      "  Model 4 -> Model 3: 1.0000\n",
      "  Model 4 -> Model 4: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Access pairwise consistency scores\n",
    "pairs, scores = embeddings.scores\n",
    "\n",
    "print(\"\\nPairwise consistency scores:\")\n",
    "for (i, j), s in zip(pairs, scores):\n",
    "    print(f\"  Model {i} -> Model {j}: {s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      " [[1.         0.99999872 0.99999922 0.99999964 0.99999706]\n",
      " [0.99999872 1.         0.99999658 0.99999903 0.9999926 ]\n",
      " [0.99999922 0.99999658 1.         0.99999911 0.9999992 ]\n",
      " [0.99999964 0.99999903 0.99999911 1.         0.99999672]\n",
      " [0.99999706 0.9999926  0.9999992  0.99999672 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# or use built in utils to convert to dense matrix\n",
    "score_matrix = ituna.utils.sparse_to_dense(\n",
    "    *embeddings.scores,\n",
    "    shape=(len(embeddings.embeddings), len(embeddings.embeddings)),\n",
    ")\n",
    "print(\"Scores:\\n\", score_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PairwiseConsistency Options\n",
    "\n",
    "The `PairwiseConsistency` transform has several options:\n",
    "\n",
    "- **`indeterminacy`**: The indeterminacy class to use for alignment\n",
    "- **`symmetric`**: If `True`, also compute j→i alignments (default: `False`)\n",
    "- **`include_diagonal`**: If `True`, include self-alignments i→i (default: `True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairwise comparisons: 3\n",
      "  Model 0 <-> Model 1: 1.0000\n",
      "  Model 0 <-> Model 2: 1.0000\n",
      "  Model 1 <-> Model 2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Example with symmetric=True\n",
    "symmetric_ensemble = ituna.ConsistencyEnsemble(\n",
    "    estimator=FastICA(n_components=5, max_iter=1000),\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=ituna.metrics.Permutation(),\n",
    "        symmetric=True,   # Include both i->j and j->i\n",
    "        include_diagonal=False,  # Exclude self-alignments\n",
    "    ),\n",
    "    random_states=3,\n",
    ")\n",
    "\n",
    "symmetric_ensemble.fit(X_ica)\n",
    "emb = symmetric_ensemble.transform(X_ica)\n",
    "\n",
    "pairs, scores = emb.scores\n",
    "print(f\"Number of pairwise comparisons: {len(pairs)}\")\n",
    "for (i, j), s in zip(pairs, scores):\n",
    "    print(f\"  Model {i} <-> Model {j}: {s:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Indeterminacy Classes\n",
    "\n",
    "You can also use any sklearn regressor as a custom indeterminacy class. The regressor is fitted to align embeddings from one model to another.\n",
    "\n",
    "For example, to use Ridge regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency score with Ridge: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Use Ridge regression as indeterminacy\n",
    "ridge_ensemble = ituna.ConsistencyEnsemble(\n",
    "    estimator=FastICA(n_components=5, max_iter=1000),\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=Ridge(alpha=0.1),  # Any sklearn regressor works\n",
    "        symmetric=False,\n",
    "    ),\n",
    "    random_states=3,\n",
    ")\n",
    "\n",
    "ridge_ensemble.fit(X_ica)\n",
    "print(f\"Consistency score with Ridge: {ridge_ensemble.score(X_ica):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "1. **`ConsistencyEnsemble`** wraps any sklearn transformer to evaluate consistency\n",
    "2. Choose the **indeterminacy class** based on your model's theoretical identifiability:\n",
    "   - `Permutation` for ICA-like models\n",
    "   - `Linear` for PCA-like models\n",
    "   - `Affine` for models like CEBRA\n",
    "3. **Consistency scores** close to 1.0 indicate reproducible representations\n",
    "4. Use **`transform()`** to access aligned embeddings and detailed pairwise scores\n",
    "\n",
    "Next, check out the [Backends tutorial](backends.ipynb) to learn about caching and distributed computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ituna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
