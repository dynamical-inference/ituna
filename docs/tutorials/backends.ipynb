{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backends: Caching and Distributed Computing\n",
    "\n",
    "Training multiple model instances for consistency evaluation can be computationally expensive. iTuna provides several backends to help:\n",
    "\n",
    "1. **Disk caching** - Avoid re-training identical models\n",
    "2. **Distributed execution** - Train models in parallel across multiple processes\n",
    "3. **DataJoint integration** - Database-backed caching for team collaboration\n",
    "\n",
    "This tutorial covers how to configure and use these backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hkfs/home/haicore/hgf_hmgu/hgf_sfs7789/git/itune-ref/ituna/_backends/utils.py:22: UserWarning: config_dataclass is not available, saving/loading Configurable objects will not be available\n",
      "  warnings.warn(\"config_dataclass is not available, saving/loading Configurable objects will not be available\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "import ituna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for all examples\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Backend: In-Memory\n",
    "\n",
    "By default, iTuna uses the `in_memory` backend, which trains all models fresh each time without caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config: {'DEFAULT_BACKEND': 'in_memory', 'BACKEND_KWARGS': {}, 'CACHE_DIR': 'backend_store', 'FILE_LOCK_TIMEOUT': 30}\n"
     ]
    }
   ],
   "source": [
    "# Check current configuration\n",
    "print(\"Current config:\", ituna.config.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk Cache Backend\n",
    "\n",
    "The `disk_cache` backend saves trained models to disk. If you run the same model on the same data again, it loads from cache instead of re-training.\n",
    "\n",
    "This is extremely useful during exploratory analysis when you're iterating on visualization or downstream analysis without changing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated config: {'DEFAULT_BACKEND': 'disk_cache', 'BACKEND_KWARGS': {}, 'CACHE_DIR': 'backend_store', 'FILE_LOCK_TIMEOUT': 30}\n"
     ]
    }
   ],
   "source": [
    "# Enable disk caching globally\n",
    "ituna.config.DEFAULT_BACKEND = \"disk_cache\"\n",
    "\n",
    "print(\"Updated config:\", ituna.config.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run (training):\n",
      "Score: 0.7096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hgf_hmgu/hgf_sfs7789/miniconda3/envs/ituna/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "/home/hgf_hmgu/hgf_sfs7789/miniconda3/envs/ituna/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "/home/hgf_hmgu/hgf_sfs7789/miniconda3/envs/ituna/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create and fit an ensemble - models will be cached\n",
    "ensemble = ituna.ConsistencyEnsemble(\n",
    "    estimator=FastICA(n_components=5, max_iter=500),\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=ituna.metrics.Permutation(),\n",
    "    ),\n",
    "    random_states=3,\n",
    ")\n",
    "\n",
    "# First run: trains and caches models\n",
    "print(\"First run (training):\")\n",
    "ensemble.fit(X)\n",
    "print(f\"Score: {ensemble.score(X):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second run (loading from cache):\n",
      "Score: 0.7096\n"
     ]
    }
   ],
   "source": [
    "# Second run: loads from cache (much faster)\n",
    "print(\"\\nSecond run (loading from cache):\")\n",
    "ensemble2 = ituna.ConsistencyEnsemble(\n",
    "    estimator=FastICA(n_components=5, max_iter=500),\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=ituna.metrics.Permutation(),\n",
    "    ),\n",
    "    random_states=3,\n",
    ")\n",
    "ensemble2.fit(X)\n",
    "print(f\"Score: {ensemble2.score(X):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Invalidation\n",
    "\n",
    "The cache key is computed from:\n",
    "- Model class and all hyperparameters\n",
    "- Data hash\n",
    "- Random state\n",
    "\n",
    "If you change **any** hyperparameter, it's treated as a new model and will be trained fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New hyperparameter - trains fresh:\n",
      "Score: 0.6284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hgf_hmgu/hgf_sfs7789/miniconda3/envs/ituna/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "/home/hgf_hmgu/hgf_sfs7789/miniconda3/envs/ituna/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "/home/hgf_hmgu/hgf_sfs7789/miniconda3/envs/ituna/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Changing max_iter creates a new cache entry\n",
    "ensemble3 = ituna.ConsistencyEnsemble(\n",
    "    estimator=FastICA(n_components=5, max_iter=501),  # Different max_iter!\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=ituna.metrics.Permutation(),\n",
    "    ),\n",
    "    random_states=3,\n",
    ")\n",
    "\n",
    "print(\"New hyperparameter - trains fresh:\")\n",
    "ensemble3.fit(X)\n",
    "print(f\"Score: {ensemble3.score(X):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Cache Directory\n",
    "\n",
    "By default, models are cached in `./backend_store`. You can customize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache directory: ./my_model_cache\n"
     ]
    }
   ],
   "source": [
    "# Set custom cache directory\n",
    "ituna.config.CACHE_DIR = \"./my_model_cache\"\n",
    "\n",
    "print(f\"Cache directory: {ituna.config.CACHE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Caching\n",
    "\n",
    "The disk cache is robust to concurrent access, so you can:\n",
    "\n",
    "- Share a cache directory across multiple notebooks\n",
    "- Share a cache with collaborators (e.g., on a network drive)\n",
    "\n",
    "If someone has already trained a model with the same configuration on the same data, you'll load their cached model instead of re-training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Context Managers\n",
    "\n",
    "Instead of changing global config, you can use context managers for temporary settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside context: disk_cache\n",
      "Outside context: in_memory\n"
     ]
    }
   ],
   "source": [
    "# Reset to default\n",
    "ituna.config.DEFAULT_BACKEND = \"in_memory\"\n",
    "\n",
    "# Use disk cache only within this block\n",
    "with ituna.config.config_context(DEFAULT_BACKEND=\"disk_cache\"):\n",
    "    print(\"Inside context:\", ituna.config.get_config()[\"DEFAULT_BACKEND\"])\n",
    "    ensemble.fit(X)\n",
    "\n",
    "print(\"Outside context:\", ituna.config.get_config()[\"DEFAULT_BACKEND\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Backend\n",
    "\n",
    "The `disk_cache_distributed` backend trains models in parallel across multiple processes. This is useful when:\n",
    "\n",
    "- You have a multi-core machine and want to utilize all cores\n",
    "- Training many models (large `random_states` value)\n",
    "\n",
    "### Auto Mode\n",
    "\n",
    "In `auto` mode, iTuna automatically spawns worker processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed config: {'DEFAULT_BACKEND': 'disk_cache_distributed', 'BACKEND_KWARGS': {'trigger_type': 'auto', 'num_workers': 4}, 'CACHE_DIR': './my_model_cache', 'FILE_LOCK_TIMEOUT': 30}\n"
     ]
    }
   ],
   "source": [
    "# Configure distributed backend with auto workers\n",
    "ituna.config.DEFAULT_BACKEND = \"disk_cache_distributed\"\n",
    "ituna.config.BACKEND_KWARGS = {\n",
    "    \"trigger_type\": \"auto\",\n",
    "    \"num_workers\": 4,  # Number of parallel processes\n",
    "}\n",
    "\n",
    "print(\"Distributed config:\", ituna.config.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models: 100%|██████████| 10/10 [00:04<00:00,  2.46it/s, trained=10/10, errors=0, reserved=0, sweep_trained=10/10, sweep_errors=0, sweep_reserved=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6479\n"
     ]
    }
   ],
   "source": [
    "# Train with 10 random states in parallel\n",
    "ensemble_parallel = ituna.ConsistencyEnsemble(\n",
    "    estimator=FastICA(n_components=5, max_iter=500),\n",
    "    consistency_transform=ituna.metrics.PairwiseConsistency(\n",
    "        indeterminacy=ituna.metrics.Permutation(),\n",
    "    ),\n",
    "    random_states=10,\n",
    ")\n",
    "\n",
    "ensemble_parallel.fit(X)\n",
    "print(f\"Score: {ensemble_parallel.score(X):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Mode (for HPC clusters)\n",
    "\n",
    "In `manual` mode, iTuna prints a command that you can run on external compute nodes (e.g., SLURM jobs). This is ideal for HPC environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure manual distributed backend\n",
    "ituna.config.DEFAULT_BACKEND = \"disk_cache_distributed\"\n",
    "ituna.config.BACKEND_KWARGS = {\n",
    "    \"trigger_type\": \"manual\",\n",
    "    \"sweep_type\": \"constant\",\n",
    "    \"sweep_name\": \"my_experiment_sweep\",\n",
    "}\n",
    "\n",
    "# When you call fit(), it will print the worker command\n",
    "# and wait for external workers to complete the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLI Worker Commands\n",
    "\n",
    "iTuna provides command-line tools for running workers:\n",
    "\n",
    "```bash\n",
    "# Local distributed backend\n",
    "ituna-fit-distributed --sweep-name <uuid> --cache-dir ./backend_store\n",
    "\n",
    "# With DataJoint backend\n",
    "ituna-fit-distributed-datajoint --sweep-name <uuid> --schema-name myschema\n",
    "```\n",
    "\n",
    "These can be submitted as SLURM jobs or run on any machine with access to the cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataJoint Backend\n",
    "\n",
    "For team collaboration with database-backed caching, use the DataJoint backend.\n",
    "\n",
    "### Setup\n",
    "\n",
    "1. Install DataJoint support:\n",
    "   ```bash\n",
    "   pip install ituna[datajoint]\n",
    "   ```\n",
    "\n",
    "2. Configure database credentials in `.env` (see `.env.template`):\n",
    "   ```\n",
    "   DJ_HOST=your-database-host\n",
    "   DJ_USER=your-username\n",
    "   DJ_PASS=your-password\n",
    "   ```\n",
    "\n",
    "3. Use the backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataJoint backend configuration (requires setup)\n",
    "# config.DEFAULT_BACKEND = \"datajoint\"\n",
    "# config.BACKEND_KWARGS = {\n",
    "#     \"trigger_type\": \"auto\",\n",
    "#     \"num_workers\": 4,\n",
    "#     \"schema_name\": \"my_ituna_schema\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Backend | Use Case |\n",
    "|---------|----------|\n",
    "| `in_memory` | Quick experiments, no caching needed |\n",
    "| `disk_cache` | Iterative analysis, avoid re-training |\n",
    "| `disk_cache_distributed` | Large sweeps, multi-core machines |\n",
    "| `datajoint` | Team collaboration, shared database |\n",
    "\n",
    "Key configuration options:\n",
    "\n",
    "```python\n",
    "import ituna\n",
    "\n",
    "# Set backend globally\n",
    "ituna.config.DEFAULT_BACKEND = \"disk_cache\"\n",
    "ituna.config.CACHE_DIR = \"./my_cache\"\n",
    "\n",
    "# Or use context manager\n",
    "with ituna.config.config_context(DEFAULT_BACKEND=\"disk_cache\"):\n",
    "    ensemble.fit(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to defaults for clean state\n",
    "ituna.config.DEFAULT_BACKEND = \"in_memory\"\n",
    "ituna.config.BACKEND_KWARGS = {}\n",
    "ituna.config.CACHE_DIR = \"backend_store\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ituna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
